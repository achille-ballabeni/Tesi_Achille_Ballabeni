{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Download datasets."
      ],
      "metadata": {
        "id": "YJRqa9s3S-4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/file/d/1aQ_mpyoxlQ2OgJ7vXkPk04sogAIpbyNF/view?usp=sharing --fuzzy\n",
        "!gdown https://drive.google.com/file/d/1-1bTtmmSau_o4MHBqT_FizS0-x_TwH4z/view?usp=sharing --fuzzy\n",
        "!gdown https://drive.google.com/file/d/1-4T8FSnJK0PZmOuwS295BTg68lA5Q49-/view?usp=sharing --fuzzy\n",
        "!gdown https://drive.google.com/file/d/1-7gXamdIWTDISiyOu40bd0xCfg1Q4a-O/view?usp=sharing --fuzzy\n",
        "!gdown https://drive.google.com/file/d/1-8A598Uqj2RV705DaFF5HdM2X12bowFx/view?usp=sharing --fuzzy"
      ],
      "metadata": {
        "id": "13sEbFkqTGvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR49SNx8Q4D1"
      },
      "source": [
        "Save images contained in the different TFRecord partitions to individual npy files in different folders, as well as the corresponding ground truth values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCOB2A10KIn9"
      },
      "source": [
        "test_tfrecords_path = '/content/split_{}.record'\n",
        "csv_path = '/content/ground_truth_{}.csv'\n",
        "output_path='/content/test_data{}/'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1G2vF54LHlG"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def load_tf_records(filepath):\n",
        "    filenames = tf.io.gfile.glob(filepath)\n",
        "    dataset = tf.data.TFRecordDataset(filenames,num_parallel_reads=tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def tf_records_file_features_description():\n",
        "    image_feature_description = {\n",
        "        \n",
        "        'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'image': tf.io.FixedLenFeature([],tf.string),\n",
        "        'label/P': tf.io.FixedLenFeature([], tf.float32),\n",
        "        'label/K': tf.io.FixedLenFeature([], tf.float32),\n",
        "        'label/Mg': tf.io.FixedLenFeature([], tf.float32),\n",
        "        'label/Ph': tf.io.FixedLenFeature([], tf.float32),\n",
        "    }\n",
        "    return image_feature_description\n",
        "\n",
        "def decode_dataset(example_proto):\n",
        "    features=tf.io.parse_single_example(example_proto, tf_records_file_features_description())\n",
        "\n",
        "    image=features['image']\n",
        "    height=features['image/height']\n",
        "    width=features['image/width']\n",
        "    image=tf.io.decode_raw(image,tf.int16)\n",
        "    image=tf.reshape(image,[height,width,150])\n",
        "\n",
        "    P=features['label/P']\n",
        "    K=features['label/K']\n",
        "    Mg=features['label/Mg']\n",
        "    Ph=features['label/Ph']\n",
        "\n",
        "    height=features['image/height']\n",
        "    width=features['image/width']\n",
        "\n",
        "    label=[P,K,Mg,Ph]\n",
        "\n",
        "    return image, label, height, width"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "i=0\n",
        "\n",
        "for k in range(1,6):\n",
        "    os.mkdir('/content/test_data'+str(k))\n",
        "    dataset = load_tf_records(test_tfrecords_path.format(k)).map(decode_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    gt = np.array(list(dataset.map(lambda image, label, height, width: label)))\n",
        "    gt = pd.DataFrame(data=gt, columns=[\"P\", \"K\", \"Mg\", \"pH\"])\n",
        "    gt.to_csv(csv_path.format(k,k), index_label=\"sample_index\")\n",
        "\n",
        "    for image, label, height, width in dataset:\n",
        "        np.save(output_path.format(k) + str(i) + '.npy', image)\n",
        "        i += 1\n",
        "\n",
        "    print('Successfully converted split_'+str(k)+'.record')\n",
        "    i = 0"
      ],
      "metadata": {
        "id": "Ll-KdhXl0q6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7689ec4-d1fb-42b1-f7ba-a4fc9db9f248"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully converted split_1.record\n",
            "Successfully converted split_2.record\n",
            "Successfully converted split_3.record\n",
            "Successfully converted split_4.record\n",
            "Successfully converted split_5.record\n"
          ]
        }
      ]
    }
  ]
}